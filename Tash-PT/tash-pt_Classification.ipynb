{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_twitter</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1067856049821155334</td>\n",
       "      <td>1</td>\n",
       "      <td>@tchaugip @n00bona História vence técnica faci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1070902848957964288</td>\n",
       "      <td>1</td>\n",
       "      <td>@camandis aa obrigado perfeito o seu timing ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1073158858925838336</td>\n",
       "      <td>0</td>\n",
       "      <td>moldura artística favorita entre filistinos al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1073220881344856064</td>\n",
       "      <td>0</td>\n",
       "      <td>Minha cama tá no localizada no meio nesse mome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1073347140334833664</td>\n",
       "      <td>0</td>\n",
       "      <td>@eueduramos o mundo so vai mudar quando as pes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>1068599890761129985</td>\n",
       "      <td>-1</td>\n",
       "      <td>@PastorMalafaia Concordo com Prof Olavo de Car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>1071376463230840833</td>\n",
       "      <td>-1</td>\n",
       "      <td>@ClaudiaLeitte se o clipe de saudade não for g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>1073978880787181568</td>\n",
       "      <td>1</td>\n",
       "      <td>agr o ar vai ficar ligado 24 por 48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>1074925265980145666</td>\n",
       "      <td>0</td>\n",
       "      <td>e eu que no meio de tantos problemas ainda con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>1071211276217606145</td>\n",
       "      <td>0</td>\n",
       "      <td>Ué ser gentil não é ser falso</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2787 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id_twitter  sentiment  \\\n",
       "0     1067856049821155334          1   \n",
       "1     1070902848957964288          1   \n",
       "2     1073158858925838336          0   \n",
       "3     1073220881344856064          0   \n",
       "4     1073347140334833664          0   \n",
       "...                   ...        ...   \n",
       "2782  1068599890761129985         -1   \n",
       "2783  1071376463230840833         -1   \n",
       "2784  1073978880787181568          1   \n",
       "2785  1074925265980145666          0   \n",
       "2786  1071211276217606145          0   \n",
       "\n",
       "                                                   text  \n",
       "0     @tchaugip @n00bona História vence técnica faci...  \n",
       "1     @camandis aa obrigado perfeito o seu timing ti...  \n",
       "2     moldura artística favorita entre filistinos al...  \n",
       "3     Minha cama tá no localizada no meio nesse mome...  \n",
       "4     @eueduramos o mundo so vai mudar quando as pes...  \n",
       "...                                                 ...  \n",
       "2782  @PastorMalafaia Concordo com Prof Olavo de Car...  \n",
       "2783  @ClaudiaLeitte se o clipe de saudade não for g...  \n",
       "2784                agr o ar vai ficar ligado 24 por 48  \n",
       "2785  e eu que no meio de tantos problemas ainda con...  \n",
       "2786                      Ué ser gentil não é ser falso  \n",
       "\n",
       "[2787 rows x 3 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tash-pt.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@tchaugip @n00bona História vence técnica faci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@camandis aa obrigado perfeito o seu timing ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>moldura artística favorita entre filistinos al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Minha cama tá no localizada no meio nesse mome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@eueduramos o mundo so vai mudar quando as pes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          1  @tchaugip @n00bona História vence técnica faci...\n",
       "1          1  @camandis aa obrigado perfeito o seu timing ti...\n",
       "2          0  moldura artística favorita entre filistinos al...\n",
       "3          0  Minha cama tá no localizada no meio nesse mome...\n",
       "4          0  @eueduramos o mundo so vai mudar quando as pes..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('id_twitter', inplace = True, axis = 1) #deletando coluna 'id_twitter'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2787, 2)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates() #deletando também duplicatas, se existirem\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    1018\n",
       " 1     888\n",
       "-1     881\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tchaugip @n00bona História vence técnica facilmente. A menos que seja algo experimental que traga algo muito diferente e novo, pois aí agrega ao panteao de técnicas e então é lembrado. Caso contrário é só execução.\n"
     ]
    }
   ],
   "source": [
    "print(df['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento do texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpeza do texto**\n",
    "\n",
    "Removendo acentos e caracteres especiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " @tchaugip @n00bona Historia vence tecnica facilmente A menos que seja algo experimental que traga algo muito diferente e novo pois ai agrega ao panteao de tecnicas e entao e lembrado Caso contrario e so execucao\n",
      "\n",
      " viado eu to apaixonado pelo @jaoromania  nao da amo um artista\n",
      "\n",
      " se eu tivesse um canal no youtube c um milhao de inscritos ja fazer pelo menos cada inscrito me mandar um real por mes\n",
      "\n",
      " To rindo mais to preocupado joguei dentro denovo pqp tava na onda do boldo \n",
      "\n",
      " Nao se preocupe com passado q ele sempre foi ausente\r\n",
      "Se tava tudo igual eu faco ficar diferente \n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def f_clean(df, text):\n",
    "    df['text'] = df['text'].replace(regex='[!/,.-]',value='').apply(lambda x: unicodedata.normalize('NFKD', x).encode('ascii','ignore').decode(\"utf-8\"))\n",
    "    return df\n",
    "                                                                    \n",
    "f_clean(df, df['text'])\n",
    "print('\\n',df['text'][0])\n",
    "print('\\n',df['text'][9])\n",
    "print('\\n',df['text'][1575])\n",
    "print('\\n',df['text'][2019])\n",
    "print('\\n',df['text'][1981])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Letícia\n",
      "[nltk_data]     Sousa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " @tchaugip @n00bona Historia vence tecnica facilmente A menos algo experimental traga algo diferente novo pois ai agrega panteao tecnicas entao lembrado Caso contrario so execucao\n",
      "\n",
      " viado to apaixonado @jaoromania nao amo artista\n",
      "\n",
      " canal youtube c milhao inscritos ja fazer menos cada inscrito mandar real mes\n",
      "\n",
      " To rindo to preocupado joguei dentro denovo pqp tava onda boldo\n",
      "\n",
      " Nao preocupe passado q sempre ausente Se tava tudo igual faco ficar diferente\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def f_stopwords(df, text):\n",
    "    stop_words = stopwords.words('portuguese')\n",
    "    df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "    return df\n",
    "\n",
    "f_stopwords(df, df['text'])\n",
    "print('\\n',df['text'][0])\n",
    "print('\\n',df['text'][9])\n",
    "print('\\n',df['text'][1575])\n",
    "print('\\n',df['text'][2019])\n",
    "print('\\n',df['text'][1981])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação de stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df['text']\n",
    "target = df['sentiment']\n",
    "count_vect = CountVectorizer()\n",
    "X_sample = count_vect.fit_transform(sample)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_sample_transform = tfidf_transformer.fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2787, 12576), (2787,))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = X_sample_transform, target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44086021505376344\n",
      "0.4336917562724014\n",
      "0.5125448028673835\n",
      "0.46236559139784944\n",
      "0.4229390681003584\n",
      "0.4874551971326165\n",
      "0.4265232974910394\n",
      "0.38489208633093525\n",
      "0.4568345323741007\n",
      "0.49640287769784175\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    reg = svm.SVC(kernel = 'linear', C=1).fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4014336917562724\n",
      "0.5053763440860215\n",
      "0.45878136200716846\n",
      "0.43727598566308246\n",
      "0.44802867383512546\n",
      "0.44086021505376344\n",
      "0.45878136200716846\n",
      "0.44964028776978415\n",
      "0.38848920863309355\n",
      "0.46402877697841727\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    nb = MultinomialNB().fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    print(nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3906810035842294\n",
      "0.4336917562724014\n",
      "0.46236559139784944\n",
      "0.45161290322580644\n",
      "0.4910394265232975\n",
      "0.4121863799283154\n",
      "0.5017921146953405\n",
      "0.4568345323741007\n",
      "0.45323741007194246\n",
      "0.4712230215827338\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    lr = LogisticRegression(max_iter=5000).fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36917562724014336\n",
      "0.45878136200716846\n",
      "0.4336917562724014\n",
      "0.4157706093189964\n",
      "0.4444444444444444\n",
      "0.3978494623655914\n",
      "0.3906810035842294\n",
      "0.420863309352518\n",
      "0.3776978417266187\n",
      "0.4028776978417266\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    adb = AdaBoostClassifier().fit(X_train, y_train)\n",
    "    y_pred = adb.predict(X_test)\n",
    "    print(adb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43010752688172044\n",
      "0.41935483870967744\n",
      "0.45878136200716846\n",
      "0.43010752688172044\n",
      "0.5089605734767025\n",
      "0.4229390681003584\n",
      "0.44086021505376344\n",
      "0.42805755395683454\n",
      "0.42805755395683454\n",
      "0.46402877697841727\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    ovr = OneVsRestClassifier(LinearSVC(random_state=0, max_iter=5000)).fit(X_train, y_train)\n",
    "    y_pred = ovr.predict(X_test)\n",
    "    print(ovr.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
